{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow 2.0 Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: This notebook is meant to teach you the latest version of Tensorflow 2.0. Most examples on the web today are still in 1.x, so be careful not to confuse the two when looking up documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Tensorflow 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to run this notebook on your local machine, please make sure you follow steps to install the dependencies. You will need TensorFlow version 2.0, and here are some tips to get you started. Please note that Tensorflow 2.0 is still not in a fully 100% stable release, but it's still usable and more intuitive than TF 1.x.\n",
    "\n",
    "     1. Have the latest version of Anaconda installed on your machine.\n",
    "     2. Create a new conda environment starting from Python 3.7. In this setup example, we'll call it tf_20_env.\n",
    "     3. Run the command: source activate tf_20_env\n",
    "     4. Then pip install TF 2.0 as described here: https://www.tensorflow.org/install/pip\n",
    "     \n",
    "\n",
    "A guide on creating Anaconda enviornments: https://uoa-eresearch.github.io/eresearch-cookbook/recipe/2014/11/20/conda/\n",
    "\n",
    "This will give you an new enviornemnt to play in TF 2.0. Generally, if you plan to also use TensorFlow in your other projects, you might also want to keep a seperate Conda environment or virtualenv in Python 3.7 that has Tensorflow 1.9, so you can switch back and forth at will.\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this part, we will work with the MNIST data. We will demonstrate how the built-in dataset works in TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for image in x_train[:3]:\n",
    "    plt.figure()\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting Simple: Using the Keras Sequential API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you will quickly see, there are a ton of ways in TensorFlow to build models and train them. TensorFlow has many APIs that you can use, and all these APIs can be confusing. We start this tutorial with the simplest way to build a model in TensorFlow 2.0: using the Keras Sequential API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first build the tf.keras.Sequential model by stacking layers.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0609 11:43:24.970806 25660 deprecation.py:323] From C:\\Users\\Ryu\\Anaconda3\\envs\\CS231n\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - ETA: 3:21 - loss: 2.2539 - accuracy: 0.21 - ETA: 9s - loss: 1.5468 - accuracy: 0.5595 - ETA: 12s - loss: 1.5277 - accuracy: 0.563 - ETA: 7s - loss: 1.1691 - accuracy: 0.665 - ETA: 6s - loss: 0.9741 - accuracy: 0.71 - ETA: 5s - loss: 0.8549 - accuracy: 0.75 - ETA: 4s - loss: 0.7666 - accuracy: 0.77 - ETA: 4s - loss: 0.7126 - accuracy: 0.79 - ETA: 3s - loss: 0.6652 - accuracy: 0.80 - ETA: 3s - loss: 0.6289 - accuracy: 0.82 - ETA: 3s - loss: 0.5929 - accuracy: 0.82 - ETA: 3s - loss: 0.5689 - accuracy: 0.83 - ETA: 3s - loss: 0.5463 - accuracy: 0.84 - ETA: 2s - loss: 0.5243 - accuracy: 0.84 - ETA: 2s - loss: 0.5129 - accuracy: 0.85 - ETA: 2s - loss: 0.5024 - accuracy: 0.85 - ETA: 2s - loss: 0.4943 - accuracy: 0.85 - ETA: 2s - loss: 0.4867 - accuracy: 0.85 - ETA: 2s - loss: 0.4733 - accuracy: 0.86 - ETA: 2s - loss: 0.4679 - accuracy: 0.86 - ETA: 2s - loss: 0.4600 - accuracy: 0.86 - ETA: 2s - loss: 0.4499 - accuracy: 0.87 - ETA: 2s - loss: 0.4400 - accuracy: 0.87 - ETA: 2s - loss: 0.4326 - accuracy: 0.87 - ETA: 2s - loss: 0.4248 - accuracy: 0.87 - ETA: 2s - loss: 0.4173 - accuracy: 0.88 - ETA: 2s - loss: 0.4132 - accuracy: 0.88 - ETA: 1s - loss: 0.4062 - accuracy: 0.88 - ETA: 1s - loss: 0.4002 - accuracy: 0.88 - ETA: 1s - loss: 0.3937 - accuracy: 0.88 - ETA: 1s - loss: 0.3886 - accuracy: 0.88 - ETA: 1s - loss: 0.3829 - accuracy: 0.88 - ETA: 1s - loss: 0.3763 - accuracy: 0.89 - ETA: 1s - loss: 0.3718 - accuracy: 0.89 - ETA: 1s - loss: 0.3681 - accuracy: 0.89 - ETA: 1s - loss: 0.3635 - accuracy: 0.89 - ETA: 1s - loss: 0.3592 - accuracy: 0.89 - ETA: 1s - loss: 0.3555 - accuracy: 0.89 - ETA: 1s - loss: 0.3509 - accuracy: 0.89 - ETA: 1s - loss: 0.3474 - accuracy: 0.90 - ETA: 1s - loss: 0.3439 - accuracy: 0.90 - ETA: 1s - loss: 0.3402 - accuracy: 0.90 - ETA: 1s - loss: 0.3365 - accuracy: 0.90 - ETA: 0s - loss: 0.3328 - accuracy: 0.90 - ETA: 0s - loss: 0.3299 - accuracy: 0.90 - ETA: 0s - loss: 0.3262 - accuracy: 0.90 - ETA: 0s - loss: 0.3232 - accuracy: 0.90 - ETA: 0s - loss: 0.3197 - accuracy: 0.90 - ETA: 0s - loss: 0.3169 - accuracy: 0.90 - ETA: 0s - loss: 0.3149 - accuracy: 0.90 - ETA: 0s - loss: 0.3129 - accuracy: 0.90 - ETA: 0s - loss: 0.3111 - accuracy: 0.91 - ETA: 0s - loss: 0.3087 - accuracy: 0.91 - ETA: 0s - loss: 0.3061 - accuracy: 0.91 - ETA: 0s - loss: 0.3043 - accuracy: 0.91 - ETA: 0s - loss: 0.3019 - accuracy: 0.91 - ETA: 0s - loss: 0.2990 - accuracy: 0.91 - ETA: 0s - loss: 0.2970 - accuracy: 0.91 - ETA: 0s - loss: 0.2956 - accuracy: 0.91 - ETA: 0s - loss: 0.2938 - accuracy: 0.91 - 3s 52us/sample - loss: 0.2933 - accuracy: 0.9156\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - ETA: 9s - loss: 0.1722 - accuracy: 0.93 - ETA: 2s - loss: 0.1592 - accuracy: 0.95 - ETA: 2s - loss: 0.1681 - accuracy: 0.94 - ETA: 2s - loss: 0.1667 - accuracy: 0.95 - ETA: 2s - loss: 0.1670 - accuracy: 0.95 - ETA: 2s - loss: 0.1628 - accuracy: 0.95 - ETA: 2s - loss: 0.1573 - accuracy: 0.95 - ETA: 2s - loss: 0.1558 - accuracy: 0.95 - ETA: 2s - loss: 0.1560 - accuracy: 0.95 - ETA: 2s - loss: 0.1526 - accuracy: 0.95 - ETA: 2s - loss: 0.1543 - accuracy: 0.95 - ETA: 2s - loss: 0.1571 - accuracy: 0.95 - ETA: 2s - loss: 0.1556 - accuracy: 0.95 - ETA: 2s - loss: 0.1542 - accuracy: 0.95 - ETA: 2s - loss: 0.1545 - accuracy: 0.95 - ETA: 2s - loss: 0.1556 - accuracy: 0.95 - ETA: 2s - loss: 0.1534 - accuracy: 0.95 - ETA: 2s - loss: 0.1513 - accuracy: 0.95 - ETA: 1s - loss: 0.1516 - accuracy: 0.95 - ETA: 1s - loss: 0.1514 - accuracy: 0.95 - ETA: 1s - loss: 0.1505 - accuracy: 0.95 - ETA: 1s - loss: 0.1504 - accuracy: 0.95 - ETA: 1s - loss: 0.1497 - accuracy: 0.95 - ETA: 1s - loss: 0.1489 - accuracy: 0.95 - ETA: 1s - loss: 0.1494 - accuracy: 0.95 - ETA: 1s - loss: 0.1486 - accuracy: 0.95 - ETA: 1s - loss: 0.1490 - accuracy: 0.95 - ETA: 1s - loss: 0.1494 - accuracy: 0.95 - ETA: 1s - loss: 0.1483 - accuracy: 0.95 - ETA: 1s - loss: 0.1474 - accuracy: 0.95 - ETA: 1s - loss: 0.1471 - accuracy: 0.95 - ETA: 1s - loss: 0.1469 - accuracy: 0.95 - ETA: 1s - loss: 0.1476 - accuracy: 0.95 - ETA: 1s - loss: 0.1475 - accuracy: 0.95 - ETA: 1s - loss: 0.1477 - accuracy: 0.95 - ETA: 1s - loss: 0.1475 - accuracy: 0.95 - ETA: 1s - loss: 0.1470 - accuracy: 0.95 - ETA: 1s - loss: 0.1472 - accuracy: 0.95 - ETA: 0s - loss: 0.1476 - accuracy: 0.95 - ETA: 0s - loss: 0.1473 - accuracy: 0.95 - ETA: 0s - loss: 0.1469 - accuracy: 0.95 - ETA: 0s - loss: 0.1468 - accuracy: 0.95 - ETA: 0s - loss: 0.1462 - accuracy: 0.95 - ETA: 0s - loss: 0.1457 - accuracy: 0.95 - ETA: 0s - loss: 0.1456 - accuracy: 0.95 - ETA: 0s - loss: 0.1451 - accuracy: 0.95 - ETA: 0s - loss: 0.1454 - accuracy: 0.95 - ETA: 0s - loss: 0.1448 - accuracy: 0.95 - ETA: 0s - loss: 0.1446 - accuracy: 0.95 - ETA: 0s - loss: 0.1444 - accuracy: 0.95 - ETA: 0s - loss: 0.1441 - accuracy: 0.95 - ETA: 0s - loss: 0.1442 - accuracy: 0.95 - ETA: 0s - loss: 0.1438 - accuracy: 0.95 - ETA: 0s - loss: 0.1437 - accuracy: 0.95 - ETA: 0s - loss: 0.1431 - accuracy: 0.95 - ETA: 0s - loss: 0.1435 - accuracy: 0.95 - ETA: 0s - loss: 0.1431 - accuracy: 0.95 - 3s 48us/sample - loss: 0.1429 - accuracy: 0.9572\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - ETA: 7s - loss: 0.0255 - accuracy: 1.00 - ETA: 2s - loss: 0.1153 - accuracy: 0.96 - ETA: 2s - loss: 0.1191 - accuracy: 0.96 - ETA: 2s - loss: 0.1134 - accuracy: 0.96 - ETA: 2s - loss: 0.1056 - accuracy: 0.96 - ETA: 2s - loss: 0.1091 - accuracy: 0.96 - ETA: 2s - loss: 0.1097 - accuracy: 0.96 - ETA: 2s - loss: 0.1106 - accuracy: 0.96 - ETA: 2s - loss: 0.1106 - accuracy: 0.96 - ETA: 2s - loss: 0.1111 - accuracy: 0.96 - ETA: 2s - loss: 0.1111 - accuracy: 0.96 - ETA: 2s - loss: 0.1096 - accuracy: 0.96 - ETA: 2s - loss: 0.1107 - accuracy: 0.96 - ETA: 2s - loss: 0.1111 - accuracy: 0.96 - ETA: 2s - loss: 0.1104 - accuracy: 0.96 - ETA: 2s - loss: 0.1124 - accuracy: 0.96 - ETA: 1s - loss: 0.1122 - accuracy: 0.96 - ETA: 1s - loss: 0.1115 - accuracy: 0.96 - ETA: 1s - loss: 0.1115 - accuracy: 0.96 - ETA: 1s - loss: 0.1113 - accuracy: 0.96 - ETA: 1s - loss: 0.1106 - accuracy: 0.96 - ETA: 1s - loss: 0.1101 - accuracy: 0.96 - ETA: 1s - loss: 0.1102 - accuracy: 0.96 - ETA: 1s - loss: 0.1109 - accuracy: 0.96 - ETA: 1s - loss: 0.1110 - accuracy: 0.96 - ETA: 1s - loss: 0.1116 - accuracy: 0.96 - ETA: 1s - loss: 0.1114 - accuracy: 0.96 - ETA: 1s - loss: 0.1114 - accuracy: 0.96 - ETA: 1s - loss: 0.1113 - accuracy: 0.96 - ETA: 1s - loss: 0.1117 - accuracy: 0.96 - ETA: 1s - loss: 0.1101 - accuracy: 0.96 - ETA: 1s - loss: 0.1104 - accuracy: 0.96 - ETA: 1s - loss: 0.1106 - accuracy: 0.96 - ETA: 1s - loss: 0.1105 - accuracy: 0.96 - ETA: 1s - loss: 0.1095 - accuracy: 0.96 - ETA: 1s - loss: 0.1090 - accuracy: 0.96 - ETA: 0s - loss: 0.1092 - accuracy: 0.96 - ETA: 0s - loss: 0.1088 - accuracy: 0.96 - ETA: 0s - loss: 0.1084 - accuracy: 0.96 - ETA: 0s - loss: 0.1083 - accuracy: 0.96 - ETA: 0s - loss: 0.1081 - accuracy: 0.96 - ETA: 0s - loss: 0.1083 - accuracy: 0.96 - ETA: 0s - loss: 0.1088 - accuracy: 0.96 - ETA: 0s - loss: 0.1086 - accuracy: 0.96 - ETA: 0s - loss: 0.1078 - accuracy: 0.96 - ETA: 0s - loss: 0.1082 - accuracy: 0.96 - ETA: 0s - loss: 0.1077 - accuracy: 0.96 - ETA: 0s - loss: 0.1079 - accuracy: 0.96 - ETA: 0s - loss: 0.1083 - accuracy: 0.96 - ETA: 0s - loss: 0.1083 - accuracy: 0.96 - ETA: 0s - loss: 0.1084 - accuracy: 0.96 - ETA: 0s - loss: 0.1094 - accuracy: 0.96 - ETA: 0s - loss: 0.1091 - accuracy: 0.96 - ETA: 0s - loss: 0.1088 - accuracy: 0.96 - ETA: 0s - loss: 0.1089 - accuracy: 0.96 - 3s 47us/sample - loss: 0.1093 - accuracy: 0.9670\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - ETA: 11s - loss: 0.0518 - accuracy: 1.000 - ETA: 2s - loss: 0.1018 - accuracy: 0.973 - ETA: 2s - loss: 0.0999 - accuracy: 0.97 - ETA: 2s - loss: 0.1007 - accuracy: 0.97 - ETA: 2s - loss: 0.0967 - accuracy: 0.97 - ETA: 2s - loss: 0.0975 - accuracy: 0.97 - ETA: 2s - loss: 0.0964 - accuracy: 0.97 - ETA: 2s - loss: 0.0971 - accuracy: 0.97 - ETA: 2s - loss: 0.0952 - accuracy: 0.97 - ETA: 2s - loss: 0.0924 - accuracy: 0.97 - ETA: 2s - loss: 0.0941 - accuracy: 0.97 - ETA: 2s - loss: 0.0927 - accuracy: 0.97 - ETA: 2s - loss: 0.0923 - accuracy: 0.97 - ETA: 2s - loss: 0.0917 - accuracy: 0.97 - ETA: 2s - loss: 0.0921 - accuracy: 0.97 - ETA: 2s - loss: 0.0915 - accuracy: 0.97 - ETA: 2s - loss: 0.0917 - accuracy: 0.97 - ETA: 2s - loss: 0.0918 - accuracy: 0.97 - ETA: 2s - loss: 0.0926 - accuracy: 0.97 - ETA: 1s - loss: 0.0922 - accuracy: 0.97 - ETA: 1s - loss: 0.0915 - accuracy: 0.97 - ETA: 1s - loss: 0.0906 - accuracy: 0.97 - ETA: 1s - loss: 0.0901 - accuracy: 0.97 - ETA: 1s - loss: 0.0905 - accuracy: 0.97 - ETA: 1s - loss: 0.0899 - accuracy: 0.97 - ETA: 1s - loss: 0.0897 - accuracy: 0.97 - ETA: 1s - loss: 0.0897 - accuracy: 0.97 - ETA: 1s - loss: 0.0897 - accuracy: 0.97 - ETA: 1s - loss: 0.0895 - accuracy: 0.97 - ETA: 1s - loss: 0.0888 - accuracy: 0.97 - ETA: 1s - loss: 0.0884 - accuracy: 0.97 - ETA: 1s - loss: 0.0879 - accuracy: 0.97 - ETA: 1s - loss: 0.0890 - accuracy: 0.97 - ETA: 1s - loss: 0.0895 - accuracy: 0.97 - ETA: 1s - loss: 0.0892 - accuracy: 0.97 - ETA: 1s - loss: 0.0889 - accuracy: 0.97 - ETA: 1s - loss: 0.0891 - accuracy: 0.97 - ETA: 1s - loss: 0.0892 - accuracy: 0.97 - ETA: 0s - loss: 0.0896 - accuracy: 0.97 - ETA: 0s - loss: 0.0893 - accuracy: 0.97 - ETA: 0s - loss: 0.0895 - accuracy: 0.97 - ETA: 0s - loss: 0.0899 - accuracy: 0.97 - ETA: 0s - loss: 0.0891 - accuracy: 0.97 - ETA: 0s - loss: 0.0887 - accuracy: 0.97 - ETA: 0s - loss: 0.0890 - accuracy: 0.97 - ETA: 0s - loss: 0.0887 - accuracy: 0.97 - ETA: 0s - loss: 0.0888 - accuracy: 0.97 - ETA: 0s - loss: 0.0887 - accuracy: 0.97 - ETA: 0s - loss: 0.0888 - accuracy: 0.97 - ETA: 0s - loss: 0.0888 - accuracy: 0.97 - ETA: 0s - loss: 0.0888 - accuracy: 0.97 - ETA: 0s - loss: 0.0889 - accuracy: 0.97 - ETA: 0s - loss: 0.0891 - accuracy: 0.97 - ETA: 0s - loss: 0.0891 - accuracy: 0.97 - ETA: 0s - loss: 0.0890 - accuracy: 0.97 - ETA: 0s - loss: 0.0886 - accuracy: 0.97 - ETA: 0s - loss: 0.0888 - accuracy: 0.97 - 3s 48us/sample - loss: 0.0891 - accuracy: 0.9730\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - ETA: 9s - loss: 0.0630 - accuracy: 0.96 - ETA: 2s - loss: 0.0744 - accuracy: 0.97 - ETA: 2s - loss: 0.0706 - accuracy: 0.97 - ETA: 2s - loss: 0.0740 - accuracy: 0.97 - ETA: 2s - loss: 0.0755 - accuracy: 0.97 - ETA: 2s - loss: 0.0770 - accuracy: 0.97 - ETA: 2s - loss: 0.0772 - accuracy: 0.97 - ETA: 2s - loss: 0.0758 - accuracy: 0.97 - ETA: 2s - loss: 0.0770 - accuracy: 0.97 - ETA: 2s - loss: 0.0759 - accuracy: 0.97 - ETA: 2s - loss: 0.0769 - accuracy: 0.97 - ETA: 2s - loss: 0.0765 - accuracy: 0.97 - ETA: 2s - loss: 0.0755 - accuracy: 0.97 - ETA: 2s - loss: 0.0748 - accuracy: 0.97 - ETA: 2s - loss: 0.0732 - accuracy: 0.97 - ETA: 2s - loss: 0.0733 - accuracy: 0.97 - ETA: 2s - loss: 0.0738 - accuracy: 0.97 - ETA: 1s - loss: 0.0721 - accuracy: 0.97 - ETA: 1s - loss: 0.0729 - accuracy: 0.97 - ETA: 1s - loss: 0.0732 - accuracy: 0.97 - ETA: 1s - loss: 0.0747 - accuracy: 0.97 - ETA: 1s - loss: 0.0758 - accuracy: 0.97 - ETA: 1s - loss: 0.0766 - accuracy: 0.97 - ETA: 1s - loss: 0.0757 - accuracy: 0.97 - ETA: 1s - loss: 0.0764 - accuracy: 0.97 - ETA: 1s - loss: 0.0766 - accuracy: 0.97 - ETA: 1s - loss: 0.0769 - accuracy: 0.97 - ETA: 1s - loss: 0.0765 - accuracy: 0.97 - ETA: 1s - loss: 0.0767 - accuracy: 0.97 - ETA: 1s - loss: 0.0766 - accuracy: 0.97 - ETA: 1s - loss: 0.0769 - accuracy: 0.97 - ETA: 1s - loss: 0.0772 - accuracy: 0.97 - ETA: 1s - loss: 0.0775 - accuracy: 0.97 - ETA: 1s - loss: 0.0781 - accuracy: 0.97 - ETA: 1s - loss: 0.0778 - accuracy: 0.97 - ETA: 1s - loss: 0.0781 - accuracy: 0.97 - ETA: 0s - loss: 0.0783 - accuracy: 0.97 - ETA: 0s - loss: 0.0776 - accuracy: 0.97 - ETA: 0s - loss: 0.0773 - accuracy: 0.97 - ETA: 0s - loss: 0.0776 - accuracy: 0.97 - ETA: 0s - loss: 0.0777 - accuracy: 0.97 - ETA: 0s - loss: 0.0775 - accuracy: 0.97 - ETA: 0s - loss: 0.0778 - accuracy: 0.97 - ETA: 0s - loss: 0.0776 - accuracy: 0.97 - ETA: 0s - loss: 0.0777 - accuracy: 0.97 - ETA: 0s - loss: 0.0777 - accuracy: 0.97 - ETA: 0s - loss: 0.0777 - accuracy: 0.97 - ETA: 0s - loss: 0.0775 - accuracy: 0.97 - ETA: 0s - loss: 0.0773 - accuracy: 0.97 - ETA: 0s - loss: 0.0773 - accuracy: 0.97 - ETA: 0s - loss: 0.0771 - accuracy: 0.97 - ETA: 0s - loss: 0.0774 - accuracy: 0.97 - ETA: 0s - loss: 0.0774 - accuracy: 0.97 - ETA: 0s - loss: 0.0778 - accuracy: 0.97 - ETA: 0s - loss: 0.0778 - accuracy: 0.97 - ETA: 0s - loss: 0.0776 - accuracy: 0.97 - 3s 47us/sample - loss: 0.0774 - accuracy: 0.9759\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21fefa37860>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - ETA: 0s - loss: 0.0359 - accuracy: 0.96 - ETA: 0s - loss: 0.1025 - accuracy: 0.97 - ETA: 0s - loss: 0.0980 - accuracy: 0.97 - ETA: 0s - loss: 0.0874 - accuracy: 0.97 - ETA: 0s - loss: 0.0705 - accuracy: 0.97 - 0s 22us/sample - loss: 0.0708 - accuracy: 0.9788\n",
      "\n",
      "Test accuracy: 0.9788\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9788"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More advanced: Writing a custom training loop with Gradient Tape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we transition to a more advanced usage of TensorFlow. This API will probably be the one you will use the most, as it provides for more flexibility. Note that you can specify more unique architectures with the forward pass. We will use the same MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-d45214763686>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmnist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmnist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "dataset, info = tfds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset mnist (11.06 MiB) to C:\\Users\\Ryu\\tensorflow_datasets\\mnist\\1.0.0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9b5afcd5bc84ab98b49cddaa7269f90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Dl Completed...', max=1, style=ProgressStyl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fac31fa9917c4dc48ba78ad5f0260e0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Dl Size...', max=1, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a63977af4a964434987c764ffda97c3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Extraction completed...', max=1, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Shuffling...', max=10, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0609 11:52:54.826965 25660 deprecation.py:323] From C:\\Users\\Ryu\\Anaconda3\\envs\\CS231n\\lib\\site-packages\\tensorflow_datasets\\core\\file_format_adapter.py:247: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Reading...', max=1, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Writing...', max=6000, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Reading...', max=1, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Writing...', max=6000, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Reading...', max=1, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Writing...', max=6000, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Reading...', max=1, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Writing...', max=6000, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Reading...', max=1, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Writing...', max=6000, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Reading...', max=1, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Writing...', max=6000, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Reading...', max=1, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Writing...', max=6000, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Reading...', max=1, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Writing...', max=6000, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Reading...', max=1, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Writing...', max=6000, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Reading...', max=1, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Writing...', max=6000, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Shuffling...', max=1, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Reading...', max=1, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Writing...', max=10000, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset mnist downloaded and prepared to C:\\Users\\Ryu\\tensorflow_datasets\\mnist\\1.0.0. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "# Reload the dataset \n",
    "def convert_types(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255\n",
    "    return image, label\n",
    "\n",
    "#dataset, info = tfds.load('mnist', data_dir='gs://tfds-data/datasets', with_info=True, as_supervised=True)\n",
    "dataset, info = tfds.load('mnist', with_info=True, as_supervised=True)\n",
    "\n",
    "mnist_train, mnist_test = dataset['train'], dataset['test']\n",
    "mnist_train = mnist_train.map(convert_types).shuffle(10000).batch(32)\n",
    "mnist_test = mnist_test.map(convert_types).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will go ahead and build the model using tf.keras. Note how building the model this way allows for a greater degree of control over the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(Model):\n",
    "  def __init__(self):\n",
    "    super(MyModel, self).__init__()\n",
    "    self.conv1 = Conv2D(32, 3, activation='relu')\n",
    "    self.flatten = Flatten()\n",
    "    self.d1 = Dense(128, activation='relu')\n",
    "    self.d2 = Dense(10, activation='softmax')\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.flatten(x)\n",
    "    x = self.d1(x)\n",
    "    return self.d2(x)\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to specify an optimizer and loss function, along with metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can write our train function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(image, label):\n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions = model(image)\n",
    "    loss = loss_object(label, predictions)\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "  train_loss(loss)\n",
    "  train_accuracy(label, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the tf.function annotation on the function above. This means that this function will be compiled into a graph in the backend, allowing it to run efficiently as TensorFlow can optimize the function for you. This automatic conversion of Python code to its graph representation is called AutoGraph, and this creates callable graphs from Python functions.\n",
    "\n",
    "What is this gradient tape?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(3.0)\n",
    "with tf.GradientTape() as g:\n",
    "  y = x * x\n",
    "dy_dx = g.gradient(y, x) # Will compute to 6.0\n",
    "print(dy_dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainable variables are automatically watched within the GradientTape (when trainable=True, as we will see this is not always the case later in the notebook). Variables are trainable when created by tf.Variable, but not when created via tf.constant. In those cases, if you want to compute the gradients of non-trainable variables, you can manually watch the tensors using the watch function, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(6.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(3.0)\n",
    "with tf.GradientTape() as g:\n",
    "  g.watch(x)\n",
    "  y = x * x\n",
    "dy_dx = g.gradient(y, x) # Will compute to 6.0\n",
    "print(dy_dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define our test function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(image, label):\n",
    "  predictions = model(image)\n",
    "  t_loss = loss_object(label, predictions)\n",
    "\n",
    "  test_loss(t_loss)\n",
    "  test_accuracy(label, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.08997425436973572, Accuracy: 97.2491683959961, Test Loss: 0.05835776776075363, Test Accuracy: 98.20999908447266\n",
      "Epoch 2, Loss: 0.06751000136137009, Accuracy: 97.92444610595703, Test Loss: 0.05647529661655426, Test Accuracy: 98.24500274658203\n",
      "Epoch 3, Loss: 0.05446019768714905, Accuracy: 98.31583404541016, Test Loss: 0.059090256690979004, Test Accuracy: 98.30667114257812\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 3\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  for image, label in mnist_train:\n",
    "    train_step(image, label)\n",
    "\n",
    "  for test_image, test_label in mnist_test:\n",
    "    test_step(test_image, test_label)\n",
    "\n",
    "  template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "  print (template.format(epoch+1,\n",
    "                         train_loss.result(),\n",
    "                         train_accuracy.result()*100,\n",
    "                         test_loss.result(),\n",
    "                         test_accuracy.result()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_labels = train_labels[:1000]\n",
    "test_labels = test_labels[:1000]\n",
    "\n",
    "train_images = train_images[:1000].reshape(-1, 28 * 28) / 255.0\n",
    "test_images = test_images[:1000].reshape(-1, 28 * 28) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Returns a short sequential model\n",
    "def create_model():\n",
    "  model = tf.keras.models.Sequential([\n",
    "    keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "  ])\n",
    "\n",
    "  model.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  return model\n",
    "\n",
    "\n",
    "# Create a basic model instance\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      " 576/1000 [================>.............] - ETA: 2s - loss: 2.3448 - accuracy: 0.15 - ETA: 0s - loss: 1.4515 - accuracy: 0.6146\n",
      "Epoch 00001: saving model to training_1/cp.ckpt\n",
      "1000/1000 [==============================] - 0s 428us/sample - loss: 1.1418 - accuracy: 0.6990 - val_loss: 0.7070 - val_accuracy: 0.7800\n",
      "Epoch 2/10\n",
      " 576/1000 [================>.............] - ETA: 0s - loss: 0.4365 - accuracy: 0.90 - ETA: 0s - loss: 0.4372 - accuracy: 0.8663\n",
      "Epoch 00002: saving model to training_1/cp.ckpt\n",
      "1000/1000 [==============================] - 0s 174us/sample - loss: 0.4227 - accuracy: 0.8770 - val_loss: 0.5494 - val_accuracy: 0.8270\n",
      "Epoch 3/10\n",
      " 576/1000 [================>.............] - ETA: 0s - loss: 0.2439 - accuracy: 0.96 - ETA: 0s - loss: 0.2688 - accuracy: 0.9323\n",
      "Epoch 00003: saving model to training_1/cp.ckpt\n",
      "1000/1000 [==============================] - 0s 185us/sample - loss: 0.2831 - accuracy: 0.9270 - val_loss: 0.4602 - val_accuracy: 0.8540\n",
      "Epoch 4/10\n",
      " 992/1000 [============================>.] - ETA: 0s - loss: 0.1477 - accuracy: 0.96 - ETA: 0s - loss: 0.2342 - accuracy: 0.95 - ETA: 0s - loss: 0.2165 - accuracy: 0.9556\n",
      "Epoch 00004: saving model to training_1/cp.ckpt\n",
      "1000/1000 [==============================] - 0s 199us/sample - loss: 0.2153 - accuracy: 0.9560 - val_loss: 0.4406 - val_accuracy: 0.8640\n",
      "Epoch 5/10\n",
      " 544/1000 [===============>..............] - ETA: 0s - loss: 0.0856 - accuracy: 1.00 - ETA: 0s - loss: 0.1522 - accuracy: 0.9743\n",
      "Epoch 00005: saving model to training_1/cp.ckpt\n",
      "1000/1000 [==============================] - 0s 184us/sample - loss: 0.1528 - accuracy: 0.9660 - val_loss: 0.4075 - val_accuracy: 0.8630\n",
      "Epoch 6/10\n",
      " 608/1000 [=================>............] - ETA: 0s - loss: 0.2280 - accuracy: 0.93 - ETA: 0s - loss: 0.1259 - accuracy: 0.9786\n",
      "Epoch 00006: saving model to training_1/cp.ckpt\n",
      "1000/1000 [==============================] - 0s 189us/sample - loss: 0.1122 - accuracy: 0.9830 - val_loss: 0.4170 - val_accuracy: 0.8660\n",
      "Epoch 7/10\n",
      " 544/1000 [===============>..............] - ETA: 0s - loss: 0.0637 - accuracy: 1.00 - ETA: 0s - loss: 0.0858 - accuracy: 0.9871\n",
      "Epoch 00007: saving model to training_1/cp.ckpt\n",
      "1000/1000 [==============================] - 0s 187us/sample - loss: 0.0878 - accuracy: 0.9870 - val_loss: 0.4146 - val_accuracy: 0.8660\n",
      "Epoch 8/10\n",
      " 576/1000 [================>.............] - ETA: 0s - loss: 0.0569 - accuracy: 1.00 - ETA: 0s - loss: 0.0659 - accuracy: 0.9878\n",
      "Epoch 00008: saving model to training_1/cp.ckpt\n",
      "1000/1000 [==============================] - 0s 174us/sample - loss: 0.0683 - accuracy: 0.9910 - val_loss: 0.4119 - val_accuracy: 0.8630\n",
      "Epoch 9/10\n",
      " 608/1000 [=================>............] - ETA: 0s - loss: 0.0456 - accuracy: 1.00 - ETA: 0s - loss: 0.0436 - accuracy: 1.0000\n",
      "Epoch 00009: saving model to training_1/cp.ckpt\n",
      "1000/1000 [==============================] - 0s 168us/sample - loss: 0.0513 - accuracy: 0.9990 - val_loss: 0.4265 - val_accuracy: 0.8590\n",
      "Epoch 10/10\n",
      " 608/1000 [=================>............] - ETA: 0s - loss: 0.0195 - accuracy: 1.00 - ETA: 0s - loss: 0.0335 - accuracy: 1.0000\n",
      "Epoch 00010: saving model to training_1/cp.ckpt\n",
      "1000/1000 [==============================] - 0s 171us/sample - loss: 0.0369 - accuracy: 1.0000 - val_loss: 0.4008 - val_accuracy: 0.8790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21ff18133c8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create checkpoint callback\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "model.fit(train_images, train_labels,  epochs = 10,\n",
    "          validation_data = (test_images,test_labels),\n",
    "          callbacks = [cp_callback])  # pass callback to training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - ETA: 0s - loss: 2.4250 - accuracy: 0.03 - 0s 75us/sample - loss: 2.3513 - accuracy: 0.1010\n",
      "Untrained model, accuracy: 10.10%\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "loss, acc = model.evaluate(test_images, test_labels)\n",
    "print(\"Untrained model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - ETA: 0s - loss: 0.1798 - accuracy: 0.93 - 0s 36us/sample - loss: 0.4008 - accuracy: 0.8790\n",
      "Restored model, accuracy: 87.90%\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(checkpoint_path)\n",
    "loss,acc = model.evaluate(test_images, test_labels)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the entire model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0609 12:00:40.760419 25660 util.py:244] Unresolved object in checkpoint: (root).optimizer.iter\n",
      "W0609 12:00:40.761410 25660 util.py:244] Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "W0609 12:00:40.762402 25660 util.py:244] Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "W0609 12:00:40.763364 25660 util.py:244] Unresolved object in checkpoint: (root).optimizer.decay\n",
      "W0609 12:00:40.764363 25660 util.py:244] Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "W0609 12:00:40.765359 25660 util.py:252] A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - ETA: 2s - loss: 2.2807 - accuracy: 0.25 - ETA: 0s - loss: 1.5669 - accuracy: 0.51 - 0s 242us/sample - loss: 1.1936 - accuracy: 0.6470\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.4418 - accuracy: 0.87 - ETA: 0s - loss: 0.4505 - accuracy: 0.86 - 0s 94us/sample - loss: 0.4302 - accuracy: 0.8730\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.3295 - accuracy: 0.93 - ETA: 0s - loss: 0.3213 - accuracy: 0.91 - 0s 99us/sample - loss: 0.3038 - accuracy: 0.9190\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.2522 - accuracy: 0.93 - ETA: 0s - loss: 0.2122 - accuracy: 0.95 - 0s 99us/sample - loss: 0.2153 - accuracy: 0.9490\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.1968 - accuracy: 0.96 - ETA: 0s - loss: 0.1609 - accuracy: 0.96 - 0s 97us/sample - loss: 0.1540 - accuracy: 0.9690\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "\n",
    "# Save entire model to a HDF5 file\n",
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Recreate the exact same model, including weights and optimizer.\n",
    "new_model = keras.models.load_model('my_model.h5')\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - ETA: 0s - loss: 0.1960 - accuracy: 0.93 - 0s 79us/sample - loss: 0.4088 - accuracy: 0.8650\n",
      "Restored model, accuracy: 86.50%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = new_model.evaluate(test_images, test_labels)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all Together: Transfer Learning Using Pretrained Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will train a model to distinguish between cats and dogs. We will leverage pretrained models for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin my loading in the dataset, and quickly visualizing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset cats_vs_dogs (786.68 MiB) to C:\\Users\\Ryu\\tensorflow_datasets\\cats_vs_dogs\\2.0.1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f212bfe4f6e64cc099516a95a3b26989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Dl Completed...', max=1, style=ProgressStyl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cf60aa42ed74fada18132ed7db0281d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='Dl Size...', max=1, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SPLIT_WEIGHTS = (8, 1, 1)\n",
    "splits = tfds.Split.TRAIN.subsplit(weighted=SPLIT_WEIGHTS)\n",
    "\n",
    "(raw_train, raw_validation, raw_test), metadata = tfds.load(\n",
    "    'cats_vs_dogs', split=list(splits),\n",
    "    with_info=True, as_supervised=True)\n",
    "\n",
    "get_label_name = metadata.features['label'].int2str\n",
    "\n",
    "for image, label in raw_train.take(2):\n",
    "    plt.figure()\n",
    "    plt.imshow(image)\n",
    "    plt.title(get_label_name(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will preprocess and shuffle the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 128 # All images will be resized to 160x160\n",
    "\n",
    "def format_example(image, label):\n",
    "  image = tf.cast(image, tf.float32)\n",
    "  image = (image/127.5) - 1\n",
    "  image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "  return image, label\n",
    "\n",
    "train = raw_train.map(format_example)\n",
    "validation = raw_validation.map(format_example)\n",
    "test = raw_test.map(format_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "SHUFFLE_BUFFER_SIZE = 1000\n",
    "train_batches = train.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "validation_batches = validation.batch(BATCH_SIZE)\n",
    "test_batches = test.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have taken care of our data, we will obtain a pretrained model. For this, we will use the MobileNet model (https://arxiv.org/abs/1801.04381). Note that we are using both its architecture, as well as pretrain weights for the model, trained on imagenet. This architecture will act as a feature extractor for us, and that is why we call it \"base_model\". We will then feed the features it extracts into more layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "# Create the base model from the pre-trained model MobileNet V2\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to get an idea of this pretrained model, we will pass in a batch of images through it, and examine our output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, label_batch in train_batches.take(1):\n",
    "    feature_batch = base_model(image_batch)\n",
    "    print(feature_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the input was (16, 128, 128, 3), with batch size as the first dimension. Thus, this feature extractor we have defined converts each 128x128x3 image to a 5x5x128 feature block. Since we only want to use the pretrained model as a feature extractor, we can go ahead and freeze the base. This means that we do not modify the weights of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we add in the last part of the model, which we will train. First, we will add some average pooling to convert features to a single 1280-element vector per image. After we have that, we will add a single dense layer that outputs the classifications of the images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "feature_batch_average = global_average_layer(feature_batch)\n",
    "print(feature_batch_average.shape)\n",
    "\n",
    "\n",
    "prediction_layer = keras.layers.Dense(1)\n",
    "prediction_batch = prediction_layer(feature_batch_average)\n",
    "print(prediction_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  base_model,\n",
    "  global_average_layer,\n",
    "  prediction_layer\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "num_train, num_val, num_test = (\n",
    "  metadata.splits['train'].num_examples*weight/10\n",
    "  for weight in SPLIT_WEIGHTS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_epochs = 10\n",
    "steps_per_epoch = round(num_train)//BATCH_SIZE\n",
    "validation_steps = 20\n",
    "\n",
    "loss0,accuracy0 = model.evaluate(validation_batches, steps = validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_batches,\n",
    "                    epochs=initial_epochs,\n",
    "                    validation_data=validation_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS231n",
   "language": "python",
   "name": "cs231n"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
